---
title: 说一说核方法（一）——核方法与核函数简介
date: 2017-08-13 16:38:35
categories: ML
tags:
     - Kernel
     - SVM
     - RKHS
description: 本文介绍了对核方法和核函数的一些理解。
---

本文由好友史博士点~~播~~写。

昨日史博士忽然来问我博客可以点播主题吗？大家都知道我这个人一沾数学就是兴奋的，于是就同意了。
因此史博士就提到了对于核函数（kernel function）这个东西不容易说明白的话题，还有关于核函数是否就是将一个低维映射到高维的问题。

相信很多人都对这个存在一些问题，原因是很多大牛在讲课的时候都是只讲果不讲因的，所以让初学者吃了很多亏，不知道核（kernel）这个东西是一个独立概念。
这个东西**大概的确**（这里使用了鲁迅体）也没法在机器学习课程中讲解，因为需要涉及到一些泛函知识。
那么，这些知识将在本系列的第二篇——“掉粉”文中进行讲解（因为是纯数文）。

这篇文章的话，说以下几个事情：

1. kernel 这个东西在 SVM 中真的只是一少部分，为了面试的话大概了解一下就可以了，面试官也很少有懂的。并不是说大家不爱学习，而是做 kernel 的人根本不关心 SVM 是什么，做 SVM 的人也根本不用关心 kernel 是个什么鬼。

2. **kernel 和 SVM 是两个完全没有关系的概念。**实际上在 SVM 提出以前，人们就提出了再生核希尔伯特空间（reproducing kernel Hilbert space，RKHS）这个概念，并且把它应用在信号处理中。如：在信号检测（signal detection）问题中，对于一条时间序列（time series），我如何知道它是一个随机步行（random walk）的噪音序列呢？还是有一个特定的模式（pattern）在里面呢？在这个情景下，RKHS 理论就给出了一个通过求解似然率（likelihood ratio）的假设检验方案，其中的 kernel 是某个随机过程在两个不同时间点的相关性（correlation）。

   另外，核方法可以用在 逻辑斯谛回归（logistic regression）、最小二乘法（least square）、降维（dimension reduction）等多处地方，也不是只和 SVM 这个概念绑定的。

3. **很多人觉得 kernel 定义了一个从低维到高维的映射，这是不准确的。**首先不是所有空间都有维度定义，比如高斯核（Gaussian kernel）——也称径向基函数（radial basis function，RBF 核）就把低维映射到了无穷维，无穷维实际上是不知道多少维的（虽然确实也是映射到了高维），所以如果强调不同的维度就是不同的空间的话，无穷维时就无法区分不同的 RKHS 之间有什么不同了。

4. 那么这个映射是什么呢？它其实描述的是一个跟内积有关的东西。有点像是在说：如果我有一个维度很高的内积空间，那么我能找到一个映射 $\Phi : X \to \mathcal{H}, \Phi(x) = K(x, \cdot)$ （其中 $\mathcal{H}$ 是某个 RKHS 空间），它可以把这个空间中的点 $x$ 映射成为一个函数（请想象这个 RKHS 空间是由函数们组成的空间，里面的每一个点，或者说每一个元素，都是一个函数），这样，在计算高维内积时就有 $<\Phi(x), \Phi(y)>_{\mathcal{H}} = K(x, y)$ ，就转变成了计算核函数的值了。（我仿佛已经听到了掉粉的声音，我本打算在第二篇再写数学的，可是不写不清楚。~~写了更不清楚。~~）

5. 正确的想法是什么？
   事实上，我们一开始要的不是核函数，而是一个简单的映射。这个映射负责把低维映射到高维，原因是我们的数据在低维上可能是不可分的，而到了高维中就可以。

   但是我们在选这个映射时有一个条件就是“我不想算高维空间中很复杂的内积”。这个时候我们才看中了核函数，因为有一些核函数可以把低维映射到高维，并且高维的内积可以很简单的用低维的内积表示。